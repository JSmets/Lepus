{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone proposal - Deep Learning for Lepus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem to be solved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) What are the main project idea and goals?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By thinking about the capstone project, one emerged when discussing with prof. Yves Hausser from the nature management department at hepia (HES-SO Geneva) about a deep learning project of natural images. As follows, an introduction of this project is presented:\n",
    "\n",
    "The Lepus software [1] was designed to help scientists analyze wildlife images acquired using photographic traps. At present, species recognition and individual identification are carried out manually, which is very time-consuming. Note that, to get the data, local people have to access to these cameras and are present on some images. Thus, humans are also a category in itself and must be classified correctly.\n",
    "\n",
    "The objective of this project is to test Deep Learning technology to automate certain tasks such as\n",
    "\n",
    "1. detecting the presence or not of an animal/human in the image\n",
    "2. locating animals/humans using bounding boxes \n",
    "3. identifying certain species given a fixed taxon level\n",
    "4. ideally, identify each individual animal of a specific species with respect to physical characteristics (e.g. to help the Wild Life Conservation Society) e.g. [Computer Vision for Wildlife Conservation (CVWC)](https://arxiv.org/pdf/1906.05586.pdf)\n",
    "\n",
    "Each of these problematics can be independent and with another Extension EPFL school learner (*Julien Smets/Blerim Arslani*), we decided to share this project. Here is the chosen configurations for our specific capstone projects:\n",
    "\n",
    "**Project 1** *Blerim Arslani : Detection of the presence of an animal/human in the image (binomial classification)*\n",
    "\n",
    "**Project 2** *Julien Smets : Identification of the type of an animal/human in the image (multnomial classification)*\n",
    "\n",
    "Please let us shortly motivate our choice. By solving these two problematics, the saved time for nature management scientists could be very high (days of work), especially for the presence detection problem because only a small amount of images contains animals (this will be more deepely detailed below).\n",
    "Moreover, the labelled data do not include the bounding boxes which excludes the second project (here we consider only supervised learning to ensure a validation metric) and the fourth one is limited to the significant inspection variance of the manual identification and the very low amount of data available. \n",
    "\n",
    "Note that these two chosen distinct projects are individual (will not be team-based and even the dataset will be different) and can be combined together by performing the second work right after the first one in order to classify the detected animals by assuming there is no empty images (cf. diagram as follow).\n",
    "\n",
    "![Diagram of the project](images/drawioDiagram.png)\n",
    "\n",
    "As follows, you can see the project cloud for more details: \n",
    "\n",
    "- [1] https://lepus.cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project (#2) aims analysing and developping an accurate method for classifying species where there is always a species or human in the image. Since the species are represented with serious irregularly, the first question asked is: what is the best method for handling the data imbalancing. To this end, an analysis of the effects of the data balancing techniques the will be performed.\n",
    "\n",
    "In a second question mark, which learning model is the best to solve our problematic. To answer it, some test of models will be performed with different optimization parameters. \n",
    "\n",
    "As a final challenge to define the best method, some additional information will be used with ML classification techniques to further improve prediction results. This part will require some EDA using data manipulation techniques and feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) What story you would like to tell with the data and what would you like to achieve at the end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this second project, the aim is to classify correctly a group of animal species with the assuption that there is always an animal in the image. To this end, the idea is to:\n",
    "- Display, analyse and expore the data.\n",
    "- Select potential usefull information for the objective and discuss potential issues.\n",
    "- Determine experiments to use this information for best accuracy possible.\n",
    "- Validate this experiments to obtain a powerfull model for animal identification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) What is the main motivation behind your project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea following Lepus project is to reduce the high time consuming manual detection, localization and identification of animal species in photographic traps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) What is the size and format of the data that you plan to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Data information*\n",
    "The given species can be very small depending on the animal size and its distance to the camera or very large taking a large part of the image. Animals can be **occluded** by background objects (trees) of even be **partially viewed** (especially for large animals such as giraffes or elephants). In rare cases, it is possible to have more than one individual or more than one species in some images. The amount of species are in proportion irregular depending on the rarity of these species. Moreover, a majority of the given images doesn't contain any animals due to trees movement, dust tornado, butterflies, etc causing false positive captures. The proportion of empty pictures are **~60-85%** depending on the device environment.\n",
    "\n",
    "In addition, cameras have many different fields of view (FOV) and resolutions including RGB and graylevel images. The latter comes from the difference between day and night acquisition devices. Note that this results to **highly non uniform representation of species** w.r.t. different situations (day/night, background situation, etc.). As an example some species are only nocturne. \n",
    "\n",
    "Some of the images are time correlated due to animals running and get captured several times, i.e. **small timelaps images**. These set of images are already grouped by the Lepus software. These grouped images are called **independent capture event (ICE)** and numbered from 3 up to ~300 if an animal stays in front of the camera a long part of day/night."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Labels and other information*\n",
    "The labels and other images information are stored in a **CSV** file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>session_dir</th>\n",
       "      <th>file_datetime</th>\n",
       "      <th>file_period</th>\n",
       "      <th>event_id</th>\n",
       "      <th>prev_file_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>place_id</th>\n",
       "      <th>taxon_id</th>\n",
       "      <th>taxon_tsn</th>\n",
       "      <th>taxon_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>2215</td>\n",
       "      <td>2015/M1/M1_25/03240535.JPG</td>\n",
       "      <td>M1 2015</td>\n",
       "      <td>24.03.15 12:21</td>\n",
       "      <td>day</td>\n",
       "      <td>235</td>\n",
       "      <td>2214.0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>550</td>\n",
       "      <td>2015/M1/M1_21/03250415.JPG</td>\n",
       "      <td>M1 2015</td>\n",
       "      <td>24.03.15 21:07</td>\n",
       "      <td>night</td>\n",
       "      <td>134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bdeogale crassicauda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>2314</td>\n",
       "      <td>2015/M1/M1_25/03240634.JPG</td>\n",
       "      <td>M1 2015</td>\n",
       "      <td>24.03.15 13:56</td>\n",
       "      <td>day</td>\n",
       "      <td>235</td>\n",
       "      <td>2313.0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>1550</td>\n",
       "      <td>2015/M1/M1_25/03210869.JPG</td>\n",
       "      <td>M1 2015</td>\n",
       "      <td>21.03.15 13:26</td>\n",
       "      <td>day</td>\n",
       "      <td>221</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3519</th>\n",
       "      <td>3522</td>\n",
       "      <td>2015/M1/M1_35/03100038.JPG</td>\n",
       "      <td>M1 2015</td>\n",
       "      <td>10.03.15 11:42</td>\n",
       "      <td>day</td>\n",
       "      <td>481</td>\n",
       "      <td>3521.0</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_id                   file_path session_dir   file_datetime  \\\n",
       "2212     2215  2015/M1/M1_25/03240535.JPG     M1 2015  24.03.15 12:21   \n",
       "547       550  2015/M1/M1_21/03250415.JPG     M1 2015  24.03.15 21:07   \n",
       "2311     2314  2015/M1/M1_25/03240634.JPG     M1 2015  24.03.15 13:56   \n",
       "1547     1550  2015/M1/M1_25/03210869.JPG     M1 2015  21.03.15 13:26   \n",
       "3519     3522  2015/M1/M1_35/03100038.JPG     M1 2015  10.03.15 11:42   \n",
       "\n",
       "     file_period  event_id  prev_file_id  session_id  place_id taxon_id  \\\n",
       "2212         day       235        2214.0           5        16      NaN   \n",
       "547        night       134           NaN           5        12        5   \n",
       "2311         day       235        2313.0           5        16      NaN   \n",
       "1547         day       221        1549.0           5        16      NaN   \n",
       "3519         day       481        3521.0           5        23      NaN   \n",
       "\n",
       "     taxon_tsn            taxon_name  \n",
       "2212       NaN                   NaN  \n",
       "547        NaN  Bdeogale crassicauda  \n",
       "2311       NaN                   NaN  \n",
       "1547       NaN                   NaN  \n",
       "3519       NaN                   NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "csv_file = '../data/DeepLearning/DeepLearningExport.csv'\n",
    "data = pd.read_csv(csv_file)\n",
    "data.sample(frac=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where columns means:\n",
    "* flie_id [unique integer]: the identifier (ID) of the file\n",
    "* file_path [string]: the path of the file image of structure \"{year}/{grid}/{camera}/{picture}\"\n",
    "* session_dir [string]: the directory name of the file (called session)\n",
    "* file_datetime [timestamp]: the date time of the file\n",
    "* file_period [nominal/cyclic ordinal]: the period of the file (day/night/twilight)\n",
    "* event_id [integer]: ID of the independent capture evenment (ICE)\n",
    "* pred_file_id [float (integer+NaNs)]: ID of the previous file deduced from event with the same ID\n",
    "* session_id [integer]: ID of the session\n",
    "* place_id [integer]: ID of the camera's location\n",
    "* taxon_id [float (integer+NaNs)]: Id of the taxon (i.e. species or lower in animal ranking)\n",
    "* taxon_tsn [float (integer+NaNs)]: ID of the world official tsn (taxonomic serial number)\n",
    "* taxon_name [string]: common name of the taxon present in the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Images*\n",
    "The data set is given as image files separated in several folders and subfolders. These folder are classified by year/grid/camera/picture where a grid correspond to a set of 36 cameras (6x6). \n",
    "\n",
    "For the moment we have only one grid \"M1 2015\" (~2.5Gb) containing 4056 color and grayscale images with 518 (~12%) containing animals or humans. Since this amount of data is not enough for the project, a larger amount will be recieved soon. The total dataset represents a covered area of 10'000 km 2  with hundred of cameras placed in different nature spots in Tanzania. The entire dataset consist of **179k** color and grayscale images (**~99.5Gb**). All these cameras are placed in different nature spots in Tanzania. This data has been obtained since 2013 and until 2018 (more recent data remains unlabelled). \n",
    "\n",
    "![Examples of images from the M1 2015 dataset.](images/imagesExamplesSeed3.png)\n",
    "\n",
    "![Examples of images from the M1 2015 dataset.](images/imagesExamplesSeed4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) How do you expect to get, manage and process the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Recieving the data*\n",
    "The data is shared by physical transfer in order to conserve privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Preparing the data*\n",
    "\n",
    "Since the whole data is shared, as a first step, the data will be cleaned and only images containing species or humans will be kept. This will be done by cleaning the CSV file. Some humans have different taxon_name (e.g. [TEAM], TEAM, etc.). Some species have different names since they are named with their full taxon name (e.g. Genetta angolensis, Genetta maculata, Genetta sp., etc.). Checking of formats and values of the data (nominal, ordinal and timestamp, ...). \n",
    "\n",
    "In a second step, the data will be grouped by labels (species names). This allows to compute the labels proportions and other statistics such as the proportion of day/night/twilight images w.r.t. species. \n",
    "\n",
    "Feature engineering will be performed to how use day/night/twilight as powerfull information for prediction.\n",
    "\n",
    "The final step consists of extracting IDs (file_path), labels (taxon_id) and maybe other additional information depending on the methods proposed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exploratory data analysis*\n",
    "\n",
    "#### Data imbalancing\n",
    "Due to the location and the environment of photographic traps in addition to the different rarity of species, the distribution of the class can be significantly imbalanced (see figure as follows).\n",
    "\n",
    "![Example of data imbalancing on a grid (M1 2015) with 518 species or humans.](images/dataImbalancing.png)\n",
    "\n",
    "In the context of species identification, the **data imbalancing** is an important issue. Indeed, if the data is used as is, the importance of very common speices can be significantly overestimated. As an example the perfect identification of a given species representing 80% of the data set results of an accuracy of 80% no matter how precise it is on other species. As a first step data imbalancing will be experimented.\n",
    "\n",
    "#### Handle very rare species\n",
    "In case of insufficient amount of images containing some of rare species, the issues related and solutions will be determined after analysing the entire dataset. At this point, rare species can be:\n",
    "\n",
    "* ignored if present with negligible amount\n",
    "* grouped in a \"rare species\" class label\n",
    "\n",
    "These two first possible solutions have their own drawbacks. Indeed, ignoring species, and thus ignoring some classes results in 100% misclassification of these rare species. Grouping rare species in a single class can lead to trouble for determining features shared by these features and can result to low ability to classify them. This will be deepended in the project's work.\n",
    "\n",
    "#### Additionnal information\n",
    "The information of animals lifestyle is a usefull assuption used by scientists to identify species in practice. Since the camera traps are well located and include **timesteps, the day, night and twilight** can be known (see below for further details). This can also be used by adding this knowledge to infer the classification (cf. following figure). To this end, an additional experiment will be performed to determine if this information can be interesting and how it could be for the context of species classification.\n",
    "\n",
    "![Example of day/night/twilight information on a grid (M1 2015) with 518 species or humans.](images/speciesDayNightTwilight.png)\n",
    "\n",
    "Lets try computing the correlation between the taxon_id and the file_period. As shown below, there is a correlation (negative still is significant) of the file_period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_period and taxon_id correlation : -0.330\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_clr = data.dropna(subset=['taxon_id'])\n",
    "data_clr = data_clr.loc[:,['file_period','taxon_id']]\n",
    "data_clr['file_period'].replace({'day': 1,'twilight':0, 'night':-1}, inplace=True)\n",
    "data_clr.replace('Team',-1, inplace=True)\n",
    "data_clr.taxon_id = pd.to_numeric(data_clr.taxon_id, downcast='float')\n",
    "\n",
    "corrmat = data_clr.corr()\n",
    "print('file_period and taxon_id correlation : {:.3f}'.format(corrmat.loc['file_period','taxon_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now try to show the distribution of day/night/twilight for each species ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file_period\n",
       "-1    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       " 0    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       " 1    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "grp.plot(kind='hist', alpha=0.5, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the figure shows, the density of day/night/twilight images are different w.r.t. animal species. Although all these figures were comupted using only one grid, this information is relevant are more advanced EDA are planned one the entire dataset to clearly show how it is possible to use this feature for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an other potential informative feature, the information of timelaps images can also be an informative by looking to different timelaps images, it is possible to see species moving. In a special case, the difference between these images can especially show their presence or not (cf. following figure). \n",
    "\n",
    "![Example of timelaps images and their difference from the M1 2015 dataset.](images/timelaps.png)\n",
    "\n",
    "For this reason, this information will mostly impact the presence detection of species and will not being tested in this project. Note that this can be experimented in future improvment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Data pre-processing*\n",
    "\n",
    "Images also needs processing. First of all, image will be normalized:\n",
    "- resize each images by downsampling the large input image into an adapted smaller shape. This will be performed empirically to balance between complexity and information loss.\n",
    "- normalize pixel intensities. In this case, in addition to 0-1 scaling, an adaptative contrast adjustment (CLAHE from cv2) will be computed to adjust contrast and enhance locally the visibility of hidden (dark) species. Note that it also enhance the noise in low contrast areas. \n",
    "\n",
    "#### *Data augmentation*\n",
    "\n",
    "The animal often represent a sub part of the image, this can induce backgroud learning instead of the animal. To reduce this by adding some variance to the data, some data modification is needed such as noise addition, horizontal flip, rotations or shear. Other potentially usefull methods but problematic will not be used because they could remove small species such as cut out or cropping.\n",
    "\n",
    "In the need of data augmentation, several processing are considered:\n",
    "- denoising. Dealing to eventual noise (e.g. due to CLAHE), it is possible reduce it by smoothing (using Gaussian kernel) and ensure the model learning denoised data.\n",
    "- image perturbations. Some rare species can eventually be underepresented. To tackle this issue, augmentation of the data using rotation, translation, etc. can be used (ImageDataGenerator from keras).\n",
    "\n",
    "#### *Additional information processing*\n",
    "The additional data of the day/night/twilight is cyclic. Similarly to time data, it is possible to ensure locally constant difference by encoding them as day:1, twilight:0 and night:-1. This allows day and night being the highest difference possible. This idea will be analyzed in EDA over the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The analysis and methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) What are the main challenges that you envision for completing the project and how do you plan to get around each one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *A. Data Imbalacing*\n",
    "\n",
    "For for the seek of best identification model, it is needed to experiment the best methods to train our model. To this end, the project will include an analysis in order to determine the best way to use our data. A comparison will be preformed between:\n",
    "1. unbalanced data \n",
    "2. partially and fully balanced data using:\n",
    "    * Undersampling: resample our majority classes with randomly subset selection\n",
    "    * Oversampling: copy the minority classes images using different and small transformations (rotation, noise, blur, gray-level versions, etc.)\n",
    "    * Changing the *class_weight* in the model training\n",
    "3. if not enough amount of images for rare species, create a group of rare species.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *B. Transfer Learning, models structures and trainings approaches*\n",
    "\n",
    "Instead of training on a randomly initialized model, it is common to perform transfer learning on a large challenging task pre-trained model (e.g. 1000-class [ImageNet](http://www.image-net.org/)). In addition of reducing the time of training, it also helps generalization [this paper](https://arxiv.org/pdf/1411.1792.pdf). To experiment this, the following training will be performed:\n",
    "1. without transfer learning (same structure with randomly initialized weights)\n",
    "2. by fine-tuning (and freezing the other layers) with transfer learning on:\n",
    "    1. the last fully connected layers (this assumes the source and target domains are the same) and use the model as feature extractor.\n",
    "    2. on additionnal last layers (to be more task specific if both domains are different)\n",
    "\n",
    "For transfer learning, one very promising model has recently been published, on June 10th 2019, and shared, on [tensorflow](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet), by Google Research called [EfficientNet-B0](https://arxiv.org/pdf/1905.11946.pdf). This model can be scaled depending on the computer learning capability and has already been trained on 1000-class [ImageNet](http://www.image-net.org/). This can be an ideal starting point for this project.\n",
    "\n",
    "Note that since it is also possible to experiment several other classifiers (e.g. decision tree, logistic regression, random forest, SVM, etc.), for the sake of simplicity the models will be trained only using dense layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *C. Additional Information as Improvment using Machine Learning*\n",
    "\n",
    "\n",
    "Since the photographic traps are precisely located with timestamp, there is the information of solar elevation angle, thus the time of the day (day, night, twilight), which can be a powerfull information because certain species have specific lifestyle. The following experiments will be tested to compare the accuracy between the basline CNN model:\n",
    "1. without additional information\n",
    "2. with concatenating directly the first fully connected (fc) layer with the information of (day, night, twilight)\n",
    "3. with concatenating the solar elevation angle (computation allowing day/night/twilight changes at the approximate same time) using different machine learning methods:\n",
    "    * decision tree\n",
    "    * logistic regression\n",
    "    * random forest\n",
    "    * SVM\n",
    "    * dense (fc) layer\n",
    "\n",
    "The solar elevation angle should give more information since it is a (cyclic) continuous variable, in contrary to day,night,twilight which is a (cyclic) nominal feature.\n",
    "\n",
    "The following example shows the structure of the data concatenaton (e.g. here with fc layers).\n",
    "\n",
    "![Example of the additional information utilisation as improvment on a grid (M1 2015) with 518 species or humans.](images/CNN_additional_data.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) What the are steps that you plan to take to achieve the end goals?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps of the work are given as follow:\n",
    "\n",
    "1. Data **loading, cleaning and manipulation** for preparation.\n",
    "\n",
    "2. **Preprocess** the dataset using EDA and known preprocessing steps.\n",
    "\n",
    "3. **Split** it in train, validation and test sets.\n",
    "\n",
    "4. Select an adapted model and use **transfer learning** for our application.\n",
    "\n",
    "5. Train it and compute its accuracy measure. Define it as the **baseline model**.\n",
    "\n",
    "6. **Experiment** the main challenges, validate them and test the performance of the proposed models using\n",
    "    * A. data imbalance.\n",
    "    * B. different model structures and trainings.\n",
    "    * C. additionnal information as classification improvment.\n",
    "\n",
    "\n",
    "7. **Combine** best results of A, B and C to obtain a final model. Validate and test it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Show us that you have a pipeline in place and that you understand the feasibility of your project goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *1. Data Loading, Cleaning and Manipulation:*\n",
    "- Load CSV file and get images pathnames in several folder and subfolders using recusrive search.\n",
    "\n",
    "- Clean data by removing unlabelled data and any without species in it.\n",
    "\n",
    "- Manage the remaining data for easy access and processing (e.g. flow from directory).\n",
    "\n",
    "#### *2. Images Preprocessing:*\n",
    "- Preform EDA to determine best methods for using the images and the additional information (day/night/twilight).\n",
    "\n",
    "- Select state of the art preprocessing methods adapted to our problematic (e.g.**\\*** histogram equalisation, denoising, resizing, data augmentation such as noise, horizontal flip, rotations or shear).\n",
    "\n",
    "- Implement them and make them easy to use such as with flow from directory.\n",
    "\n",
    "*\\*based on iWildCam 2019 challenge [Top7 report](https://github.com/Walleclipse/iWildCam_2019_FGVC6/blob/master/iwildcam_2019_report.pdf).*\n",
    "\n",
    "#### *3. Spliting the data:*\n",
    "- Separate the data into a stratified train/validation/test sets in order to conserve the labels (species) proportions and enviroment proportions, thus by keeping its global imbalance. This will be balanced or not depending on the experiments.\n",
    "\n",
    "#### *4. Transfer Learning:* \n",
    "- Select a state of the art pretrained model.\n",
    "\n",
    "- Adapt the structure to our problem by adjusting last layers to fit our desired output.\n",
    "\n",
    "#### *5. Baseline model:*\n",
    "- Train the adapted model on our dataset.\n",
    "\n",
    "- Validate the pre-trained model.\n",
    "\n",
    "- Set this trained model as the baseline for our future experiments.\n",
    "\n",
    "#### *6. Experiments for our final goal:*\n",
    "- A. Experiment data imbalacing to set the best preprocessing method for training.\n",
    "\n",
    "- B. Apply transfer learning, models structures and trainings approaches in order to improve the learning rate and/or the test accuracy.\n",
    "\n",
    "- C. Use additional information to try to further improve the final accuracy. \n",
    "\n",
    "#### *7. Obtain our final model by comining best results:*\n",
    "- Use the knowledge learned by all the experiments to define a final model and compute its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code sample will be implemented in several python scripts (.py) for convenience and simplicity (e.g. separation of pre-processing, training and testing). An additional notebook (.ipynb) will be included with analysis details and visualization figures as a small report (similarly to this document).\n",
    "\n",
    "#### *Contribution of the proposed project*\n",
    "\n",
    "The proposed project of classifying animal species in images containing always at least one species. This work will differ on several points w.r.t. the state of the art [1,2].\n",
    "\n",
    "To obtain the top3 private score in iWildCam2019, [1] used a model ensemble of Inceptionv3, ResNet152, and InceptionResnetv2 and majority voting for classification. Moreover, they focused on methods for classifying and locating animals presence and absence in images (using DL [1] or image processing [2]) where the proposed project ignores this and assumes this is already performed. All these points will not be performed to focus on different points:\n",
    "\n",
    "* data imbalancing which was not experimented and analzed precisely.\n",
    "* using the entire image instead of a crop centered on the species.\n",
    "* concentrating the utilization on additional data information (e.g. day/night/twilight) thing they not used.\n",
    "* applying only one model instead of optimizing the accuracy exclusively using the input images.\n",
    "\n",
    "#### *References:*\n",
    "\n",
    "- [1] https://github.com/HayderYousif/iwildcam-2019-fgvc6, Github link.\n",
    "- [2] Yousif, Hayder, et al. \"Animal Scanner: Software for classifying humans, animals, and empty frames in camera trap images.\" Ecology and Evolution (2019).\n",
    "\n",
    "#### *Others*\n",
    "\n",
    "Note that the data can need to be confidential with a DNA (standard Non-Disclosure Agreement) due to some very rare species which are often hunted for money. If this is the case, it will be demanded to the EPFL soon. But anyways the precise location of the picture will not be transmitted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
