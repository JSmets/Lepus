{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone proposal - Deep Learning for LEPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem to be solved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) What are the main project idea and goals?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By thinking about the capstone project, one emerged when discussing with prof. Yves Hausser from the nature management department at hepia (HES-SO Geneva) about a deep learning project of natural images. As follows, an introduction of this project is presented:\n",
    "\n",
    "The Lepus software [1] was designed to help scientists analyze wildlife images acquired using photographic traps. At present, species recognition and individual identification are carried out manually, which is very time-consuming.\n",
    "\n",
    "The objective of this project is to test Deep Learning technology to automate certain tasks such as\n",
    "\n",
    "1. detecting the presence or not of an animal in the image\n",
    "2. locating animals using bounding boxes \n",
    "3. identifying certain species or more generally its type or family\n",
    "4. ideally, identify each individual animal of a specific specie with respect to physical characteristics (e.g. to help the Wild Life Conservation Society)\n",
    "\n",
    "Each of these problematics can be independent and with another Extension EPFL school learner (*Julien Smets*), we decided to share this project. Here is the chosen configurations for our specific capstone projects:\n",
    "\n",
    "**Project 1** *Blerim Arslani : Detection of the presence of an animal in the image (binomial classification)*\n",
    "\n",
    "**Project 2** *Julien Smets : Identification of the type of an animal in the image (multnomial classification)*\n",
    "\n",
    "Please let us shortly motivate our choice. By solving these two problematics, the saved time for nature management scientists could be very high (days of work), especially for the presence detection problem because only a small amount of images contains animals (this will be more deepely detailed below).\n",
    "Moreover, the labelled data do not include the bounding boxes which excludes the second project (here we consider only supervised learning to ensure a validation metric) and the fourth one is limited to the significant inspection variance of the manual identification and the very low amount of data available. \n",
    "\n",
    "Note that these two chosen distinct projects are individual (will not be team-based but only the dataset will) and can be combined together by performing the second work right after the first one in order to classify the detected animals (cf. diagram as follow).\n",
    "\n",
    "![title](drawioDiagram.png)\n",
    "\n",
    "\n",
    "As follows, you can see the project cloud for more details: \n",
    "\n",
    "- [1] http://ec2-35-157-78-9.eu-central-1.compute.amazonaws.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) What story you would like to tell with the data and what would you like to achieve at the end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project 1** This part of the project would be to detect with a relatively high accuracy the presence or absence of an animal.\n",
    "\n",
    "**Project 2** In this second project, the aim it to classify correctly a group of animal species with the assuption that there is always an animal in the image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) What is the main motivation behind your project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea following Lepus project is to reduce the high time consuming manual detection, localization and identification (and ideally with better accuracy that humans but it will not be experimented here) of animal species in photographic traps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) What is the size and format of the data that you plan to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Data details*\n",
    "\n",
    "The data set consists of **750'000 pictures** containing about **57 different species** including about **80% of images without any animal** on it. \n",
    "\n",
    "These images come from **hundred of cameras** placed in different nature spots in Tanzania and represent a covered area of **10'000 km$^2$**. This data has been obtained since 2008 and until 2017 (more recent data remains unlabelled). \n",
    "\n",
    "The data set is given as image files separated in several folders. The labels and other images information are stored in a **CSV** file.\n",
    "\n",
    "#### *Data information*\n",
    "\n",
    "The given species can be very small depending on the animal size and its distance to the camera or very large taking a large part of the image. Animals can be **occluded** by background objects (trees) of even be **partially viewed** (especially for large animals such as giraffes or elephants). The amount of species are in proportion irregular depending on the rarity of these species. Moreover, a majority of the given images doesn't contain any animals due to trees movement, dust tornado, butterflies, etc causing false positive captures. The proportion of empty pictures are **~60-85%** depending on the device environment.\n",
    "\n",
    "In addition, cameras have many different fields of view (FOV) and two resolutions (medium: 800x600 and high: 1024x768) including RGB and graylevel images. The latter comes from the difference between day and night acquisition devices. Note that this results to **highly non uniform representation of species** w.r.t. different situations (day/night, background situation, etc.). As an example some species are only nocturne. This will need robust data preprocessing in order to avoid biases.\n",
    "\n",
    "Some of the images are time correlated due to animals running and get captured several times, i.e. **small timelaps images**. These set of images are already grouped by the Lepus software in specific folders ready to process. These grouped images are **called evenement independant capture (EIC)** and numbered from 3 up to ~300 if an animal stays in front of the camera the whole day/night. This can be an important information and will be discussed after.\n",
    "\n",
    "#### *Others*\n",
    "\n",
    "Note that the data needs to be confidential with a DNA (standard Non-Disclosure Agreement) due to some very rare species which are often hunted for money.\n",
    "\n",
    "In addition, for pre-training purposes, several dataset from Kaggle can be used. To this aim, the following data set could be used:\n",
    "- iNaturalist 2019 at FGVC6, \n",
    "[Kaggle](https://www.kaggle.com/c/inaturalist-2019-fgvc6), \n",
    "[Paper2018](https://arxiv.org/pdf/1707.06642.pdf), \n",
    "[Github](https://github.com/visipedia/inat_comp),\n",
    "[presentation2018](https://www.dropbox.com/s/52nz6qc3zcwqhoa/iNaturalist_Competition_FGVC_2018.pdf?dl=0)\n",
    "- iWildCam 2019 at FGVC6, \n",
    "[Kaggle](https://www.kaggle.com/c/iwildcam-2019-fgvc6), \n",
    "[Github](https://github.com/visipedia/iwildcam_comp), \n",
    "[Top3 private score](https://github.com/HayderYousif/iwildcam-2019-fgvc6), \n",
    "[Top7 private score](https://github.com/Walleclipse/iWildCam_2019_FGVC6) \n",
    "([Top7 report](https://github.com/Walleclipse/iWildCam_2019_FGVC6/blob/master/iwildcam_2019_report.pdf))\n",
    "- Oregon wildlife, \n",
    "[Kaggle](https://www.kaggle.com/virtualdvid/oregon-wildlife)\n",
    "- CaltechCameraTraps, \n",
    "[website](https://beerys.github.io/CaltechCameraTraps/)\n",
    "- Snapshot Serengeti, \n",
    "[website](http://lila.science/datasets/snapshot-serengeti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) How do you expect to get, manage and process the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Recieving the data*\n",
    "The data is shared by physical transfer in order to conserve privacy. \n",
    "\n",
    "#### *Managing the data*\n",
    "Although we do not already know how exactly the data will be organized, we will need to result in the following data structure.\n",
    "\n",
    "The dataset will be split in a stratified train/validation/test sets in order to conserve the labels (species) proportions and enviroment proportions. Only the labeled data will be considered. It is possible to consider the train/validation split from 2008 to 2016 and use the most recent 2017 dataset as the testing set. \n",
    "\n",
    "#### *Data pre-processing*\n",
    "\n",
    "This dataset has a large amount properties (temporal, day/night assumptions, etc.) but this variability is also its main drawback. A good understanding of the data management and processing is needed. However, the following steps are planned.\n",
    "\n",
    "The data will be cleaned and processed a minimum by ensuring the images have normalised sizes and pixel intensities (e.g. Z-Scores) and are all labeled inculding ones without animals (label 0).\n",
    "\n",
    "The temporal information of the timelaps captures can be used as movement detectors (e.g. difference between frames or background substraction).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The analysis and methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (-) State of the art"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Transfer Learning:*\n",
    "The transfer learning consist of using a knowledge gained while solving one problem and applying it to a different but related problem. This method can highly reduce the training time and improve classification accuracy.\n",
    "\n",
    "#### *Ensemble methods:*\n",
    "The ensembling strategy is a group of methods that aim to combine advantages of multiple different models (instances of the same model, different model architectures, etc.) in order to improve the final accuracy. It is known to result in very accurate solutions as shown by the number of Kaggle competitons top winners using this method. To obtain the top3 private score in iWildCam2019, [1] used a model ensemble of Inceptionv3, ResNet152, and InceptionResnetv2 and majority voting for classification. He first located moving objects using background substraction [2].\n",
    "\n",
    "#### *Images Preprocessing:*\n",
    "In [2], the author used image processing techniques to locate moving objects using the difference of timelaps frames representing short time movements such as moving animals and vegetations. Several other steps allowed to extract animals bounding boxes.\n",
    "\n",
    "#### *References:*\n",
    "\n",
    "- [1] https://github.com/HayderYousif/iwildcam-2019-fgvc6, Github link.\n",
    "- [2] Yousif, Hayder, et al. \"Animal Scanner: Software for classifying humans, animals, and empty frames in camera trap images.\" Ecology and Evolution (2019)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) What are the main challenges that you envision for completing the project and how do you plan to get around each one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *List of challenges on images: \\**\n",
    "- **Illumination:** Images can be poorly illuminated, especially at night.\n",
    "- **Motion Blur:** The shutter speed of the camera is not fast enough to eliminate motion blur, so running animals can be blurry.\n",
    "- **Small Region Of Interest (ROI):** Some animals are small or far from the camera, and can be difficult to spot even for humans.\n",
    "- **Occlusion:** Animals can be occluded by vegetation or the edge of the frame.\n",
    "- **Perspective:** Sometimes animals come very close to the camera, causing a forced perspective.\n",
    "- **Weather Conditions:** Poor weather, such as rain, snow or dust can obstruct the camera and cause false triggers.\n",
    "- **Camera Malfunctions:** Sometimes the camera can malfunction and cause discolorations.\n",
    "- **Temporal Changes:** Given a location, backgorund can change over time as the season change.\n",
    "- **Non-animal variability:** Depending on the location, false positive triggers can significantly vary.\n",
    "\n",
    "\\*based on iWildCam 2019 challenge [Top7 report](https://github.com/Walleclipse/iWildCam_2019_FGVC6/blob/master/iwildcam_2019_report.pdf).\n",
    "\n",
    "#### *List of technical challenges:*\n",
    "- Adapted **preprocessing** steps without inducing any strong bias.\n",
    "- Be inspired by accurate existing methods and define a good **baseline**.\n",
    "- Tune, modify and improve the model as **our own solution**. \n",
    "- **Analyse** and conlcude about the accuracy of the proposed model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) What the are steps that you plan to take to achieve the end goals?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps of the work are given as follow:\n",
    "\n",
    "1. **Preprocess** the dataset and split it in train, validation and test sets.\n",
    "\n",
    "2. Select a model and use **transfer learning** for our application.\n",
    "\n",
    "3. Compute its accuracy measure (F1-score) and define it as the **baseline model**.\n",
    "\n",
    "4. **Optimize** it, validate it and test the performance of the proposed model.\n",
    "\n",
    "5. Use **ensemble methods** for additionnal improvments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Show us that you have a pipeline in place and that you understand the feasibility of your project goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *1. Preprocessing: \\**\n",
    "- White balance: Adjust saturation and tone processing problems.\n",
    "\n",
    "- Histogram equalization: Adjust the brightness of the image, but increase the contrast of noise and reduce the contrast of some useful signals.\n",
    "\n",
    "- Image denoising: Reduce the noise but also smooth edges.\n",
    "\n",
    "- Image resizing: Reduce images size.\n",
    "\n",
    "- Data enhancement: Random crop, rotation, translation, brightness and noise effects applied to the original images.\n",
    "\n",
    "- Data balancing: Weight the data enhancement w.r.t. labels to uniformize their proportions. \n",
    "\n",
    "\\*based on iWildCam 2019 challenge [Top7 report](https://github.com/Walleclipse/iWildCam_2019_FGVC6/blob/master/iwildcam_2019_report.pdf).\n",
    "\n",
    "#### *2. Transfer Learning:* \n",
    "- Select a state of the art pretrained model (**EfficientNet**, ResNet, DenseNet, Xception, etc.).\n",
    "\n",
    "- Adapt the structure to our problem (adjust last layers to fit our desired output).\n",
    "\n",
    "- Train it on our dataset.\n",
    "\n",
    "- Validate the pre-trained model.\n",
    "\n",
    "#### *3. Baseline model:*\n",
    "- Set this trained model as the baseline for our future experiments.\n",
    "\n",
    "#### *4. Optimize the model:*\n",
    "- Tune, modify (re-train first layers) and adapt the model hyperparameters, including some eventual preprocessing (filtering) or postprocessing (ensembling, bagging) steps.\n",
    "\n",
    "- Validate the new model.\n",
    "\n",
    "- Test our final model using the test set\n",
    "\n",
    "#### *5. Advanced improvements:*\n",
    "- Do transfer learning on others pretrained model.\n",
    "\n",
    "- Train and validate them on our dataset.\n",
    "\n",
    "- Optimize them separately to our problem.\n",
    "\n",
    "- Use Ensemble methods to further improve our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The communication\n",
    "\n",
    "Here you can discuss your plan for analysis and communication of your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code sample will be implemented in several python scripts (.py) for convenience and simplicity (e.g. separation of pre-processing, training and testing). An additional notebook (.ipynb) will be included with analysis details and visualization figures as a small report (similarly to this document).\n",
    "\n",
    "Please note that since both projects are similar in terms of challenges (e.g. preprocessing) and in terms of pipeline, they are distiguished by their objective (binary and multinominal classifications). This will guide us to very specific and thus different solutions as figured in the diagram as above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
